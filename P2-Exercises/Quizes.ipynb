{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script builds and runs a graph with miniflow.\n",
    "\n",
    "There is no need to change anything to solve this quiz!\n",
    "\n",
    "However, feel free to play with the network! Can you also\n",
    "build a network that solves the equation below?\n",
    "\n",
    "(x + y) + y\n",
    "\"\"\"\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/docker\"))\n",
    "from miniflow import *\n",
    "\n",
    "x, y = Input(), Input()\n",
    "\n",
    "f = Add(x, y)\n",
    "\n",
    "feed_dict = {x: 10, y: 12}\n",
    "\n",
    "sorted_neurons = topological_sort(feed_dict)\n",
    "output = forward_pass(f, sorted_neurons)\n",
    "\n",
    "# NOTE: because topological_sort set the values for the `Input` neurons we could also access\n",
    "# the value for x with x.value (same goes for y).\n",
    "print(\"{} + {} = {} (according to miniflow)\".format(feed_dict[x], feed_dict[y], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in sorted_neurons:\n",
    "    print((i.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forward_pass(f, sorted_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = forward_pass(f, sorted_neurons)\n",
    "type(sorted_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You need to change the Add() class below.\n",
    "\"\"\"\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inbound_neurons=[]):\n",
    "        # Neurons from which this Node receives values\n",
    "        self.inbound_neurons = inbound_neurons\n",
    "        # Neurons to which this Node passes values\n",
    "        self.outbound_neurons = []\n",
    "        # A calculated value\n",
    "        self.value = None\n",
    "        # Add this node as an outbound node on its inputs.\n",
    "        for n in self.inbound_neurons:\n",
    "            n.outbound_neurons.append(self)\n",
    "\n",
    "    # These will be implemented in a subclass.\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Compute the output value based on `inbound_neurons` and\n",
    "        store the result in self.value.\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "class Input(Neuron):\n",
    "    def __init__(self):\n",
    "        # an Input neuron has no inbound nodes,\n",
    "        # so no need to pass anything to the Node instantiator\n",
    "        Neuron.__init__(self)\n",
    "\n",
    "    # NOTE: Input node is the only node where the value\n",
    "    # is passed as an argument to forward().\n",
    "    #\n",
    "    # All other neuron implementations should get the value\n",
    "    # of the previous neurons from self.inbound_neurons\n",
    "    #\n",
    "    # Example:\n",
    "    # val0 = self.inbound_neurons[0].value\n",
    "    def forward(self, value=None):\n",
    "        # Overwrite the value if one is passed in.\n",
    "        if value:\n",
    "            self.value = value\n",
    "\n",
    "\n",
    "class Add(Neuron):\n",
    "    def __init__(self, x, y):\n",
    "        # You could access `x` and `y` in forward with\n",
    "        # self.inbound_nodes[0] (`x`) and self.inbound_nodes[1] (`y`)\n",
    "        Neuron.__init__(self, [x, y])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this neuron (`self.value`) to the sum of it's inbound_nodes.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "        self.value = sum([n.value for n in self.inbound_neurons])\n",
    "\n",
    "\"\"\"\n",
    "No need to change anything below here!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_neurons = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    neurons = [n for n in input_neurons]\n",
    "    while len(neurons) > 0:\n",
    "        n = neurons.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_neurons:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            neurons.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_neurons)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_neurons:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_neuron, sorted_neurons):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted neurons.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_neuron`: A neuron in the graph, should be the output neuron (have no outgoing edges).\n",
    "        `sorted_neurons`: a topologically sorted list of neurons.\n",
    "\n",
    "    Returns the output neuron's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_neurons:\n",
    "        n.forward()\n",
    "\n",
    "    return output_neuron.value\n",
    "\n",
    "\"\"\"\n",
    "This script builds and runs a graph with miniflow.\n",
    "\n",
    "There is no need to change anything to solve this quiz!\n",
    "\n",
    "However, feel free to play with the network! Can you also\n",
    "build a network that solves the equation below?\n",
    "\n",
    "(x + y) + y\n",
    "\"\"\"\n",
    "\n",
    "from miniflow import *\n",
    "\n",
    "x, y = Input(), Input()\n",
    "\n",
    "f = Add(x, y)\n",
    "\n",
    "feed_dict = {x: 10, y: 5}\n",
    "\n",
    "sorted_neurons = topological_sort(feed_dict)\n",
    "output = forward_pass(f, sorted_neurons)\n",
    "\n",
    "# NOTE: because topological_sort set the values for the `Input` neurons we could also access\n",
    "# the value for x with x.value (same goes for y).\n",
    "print(\"{} + {} = {} (according to miniflow)\".format(feed_dict[x], feed_dict[y], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bonus Challenge!\n",
    "\n",
    "Write your code in Add (scroll down).\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inbound_neurons=[], label=''):\n",
    "        # An optional description of the neuron - most useful for outputs.\n",
    "        self.label = label\n",
    "        # Neurons from which this Node receives values\n",
    "        self.inbound_neurons = inbound_neurons\n",
    "        # Neurons to which this Node passes values\n",
    "        self.outbound_neurons = []\n",
    "        # A calculated value\n",
    "        self.value = None\n",
    "        # Add this node as an outbound node on its inputs.\n",
    "        for n in self.inbound_neurons:\n",
    "            n.outbound_neurons.append(self)\n",
    "\n",
    "\n",
    "    # These will be implemented in a subclass.\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Compute the output value based on `inbound_neurons` and\n",
    "        store the result in self.value.\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Backward propagation.\n",
    "\n",
    "        Compute the gradient of the current Neuron with respect\n",
    "        to the input neurons. The gradient of the loss with respect\n",
    "        to the current Neuron should already be computed in the `gradients`\n",
    "        attribute of the output neurons.\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "class Input(Neuron):\n",
    "    def __init__(self):\n",
    "        # An Input Neuron has no inbound neurons,\n",
    "        # so no need to pass anything to the Neuron instantiator\n",
    "        Neuron.__init__(self)\n",
    "\n",
    "    # NOTE: Input Neuron is the only Neuron where the value\n",
    "    # may be passed as an argument to forward().\n",
    "    #\n",
    "    # All other Neuron implementations should get the value\n",
    "    # of the previous neurons from self.inbound_neurons\n",
    "    #\n",
    "    # Example:\n",
    "    # val0 = self.inbound_neurons[0].value\n",
    "    def forward(self, value=None):\n",
    "        # Overwrite the value if one is passed in.\n",
    "        if value:\n",
    "            self.value = value\n",
    "\n",
    "    def backward(self):\n",
    "        # An Input Neuron has no inputs so we refer to ourself\n",
    "        # for the gradient\n",
    "        self.gradients = {self: 0}\n",
    "        for n in self.outbound_neurons:\n",
    "            self.gradients[self] += n.gradients[self]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Can you augment the Add class so that it accepts\n",
    "any number of neurons as input?\n",
    "\n",
    "Hint: this may be useful:\n",
    "https://docs.python.org/3/tutorial/controlflow.html#unpacking-argument-lists\n",
    "\"\"\"\n",
    "class Add(Neuron):\n",
    "    # You may need to change this...\n",
    "    def __init__(self, *arg):\n",
    "        Neuron.__init__(self, list(arg))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        For reference, here's the old way from the last\n",
    "        quiz. You'll want to write code here.\n",
    "        \"\"\"\n",
    "        # x_value = self.inbound_neurons[0].value\n",
    "        # y_value = self.inbound_neurons[1].value\n",
    "        # self.value = x_value + y_value\n",
    "        self.value = sum([i.value for i in self.inbound_neurons])\n",
    "\n",
    "        \n",
    "class Mul(Neuron):\n",
    "    # You may need to change this...\n",
    "    def __init__(self, *arg):\n",
    "        Neuron.__init__(self, list(arg))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        For reference, here's the old way from the last\n",
    "        quiz. You'll want to write code here.\n",
    "        \"\"\"\n",
    "        # x_value = self.inbound_neurons[0].value\n",
    "        # y_value = self.inbound_neurons[1].value\n",
    "        # self.value = x_value + y_value\n",
    "        self.value = np.prod([i.value for i in self.inbound_neurons])\n",
    "        \n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the neurons in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Neuron and the value is the respective value feed to that Neuron.\n",
    "\n",
    "    Returns a list of sorted neurons.\n",
    "    \"\"\"\n",
    "\n",
    "    input_neurons = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    neurons = [n for n in input_neurons]\n",
    "    while len(neurons) > 0:\n",
    "        n = neurons.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_neurons:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            neurons.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_neurons)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_neurons:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_Neuron, sorted_neurons):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted neurons.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_Neuron`: A Neuron in the graph, should be the output Neuron (have no outgoing edges).\n",
    "        `sorted_neurons`: a topologically sorted list of neurons.\n",
    "\n",
    "    Returns the output Neuron's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_neurons:\n",
    "        n.forward()\n",
    "\n",
    "    return output_Neuron.value\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "No need to change anything here! \n",
    "\n",
    "If all goes well, this should work after you\n",
    "modify the Add class in miniflow.py.\n",
    "\"\"\"\n",
    "\n",
    "# from miniflow import *\n",
    "\n",
    "x, y, z = Input(), Input(), Input()\n",
    "\n",
    "f = Add(x, y, z)\n",
    "g = Mul(x, y, z)\n",
    "feed_dict = {x: 4, y: 5, z: 10}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "output2 = forward_pass(g, graph)\n",
    "# should output 19\n",
    "print(\"{} + {} + {} = {} (according to miniflow)\".format(feed_dict[x], feed_dict[y], feed_dict[z], output))\n",
    "print(\"{} + {} + {} = {} (according to miniflow)\".format(feed_dict[x], feed_dict[y], feed_dict[z], output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from miniflow import *\n",
    "\"\"\"\n",
    "Write the Linear#forward method below!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inbound_neurons=[]):\n",
    "        # Neurons from which this Node receives values\n",
    "        self.inbound_neurons = inbound_neurons\n",
    "        # Neurons to which this Node passes values\n",
    "        self.outbound_neurons = []\n",
    "        # A calculated value\n",
    "        self.value = None\n",
    "        # Add this node as an outbound node on its inputs.\n",
    "        for n in self.inbound_neurons:\n",
    "            n.outbound_neurons.append(self)\n",
    "\n",
    "    # These will be implemented in a subclass.\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        Compute the output value based on `inbound_neurons` and\n",
    "        store the result in self.value.\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "class Input(Neuron):\n",
    "    def __init__(self):\n",
    "        # An Input Neuron has no inbound neurons,\n",
    "        # so no need to pass anything to the Neuron instantiator\n",
    "        Neuron.__init__(self)\n",
    "\n",
    "        # NOTE: Input Neuron is the only Neuron where the value\n",
    "        # may be passed as an argument to forward().\n",
    "        #\n",
    "        # All other Neuron implementations should get the value\n",
    "        # of the previous neurons from self.inbound_neurons\n",
    "        #\n",
    "        # Example:\n",
    "        # val0 = self.inbound_neurons[0].value\n",
    "    def forward(self, value=None):\n",
    "        # Overwrite the value if one is passed in.\n",
    "        if value:\n",
    "            self.value = value\n",
    "\n",
    "\n",
    "class Linear(Neuron):\n",
    "    def __init__(self, inputs, weights, bias):\n",
    "        Neuron.__init__(self, inputs)\n",
    "        \n",
    "        # NOTE: The weights and bias properties here are not\n",
    "        # numbers, but rather references to other neurons.\n",
    "        # The weight and bias values are stored within the\n",
    "        # respective neurons.\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set self.value to the value of the linear function output.\n",
    "        \n",
    "        Your code goes here!\n",
    "        \"\"\"\n",
    "        self.value = sum([i.value*j.value for i,j in zip(self.inbound_neurons,self.weights)]) + self.bias.value\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the neurons in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Neuron and the value is the respective value feed to that Neuron.\n",
    "\n",
    "    Returns a list of sorted neurons.\n",
    "    \"\"\"\n",
    "\n",
    "    input_neurons = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    neurons = [n for n in input_neurons]\n",
    "    while len(neurons) > 0:\n",
    "        n = neurons.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_neurons:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            neurons.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_neurons)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_neurons:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_Neuron, sorted_neurons):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted neurons.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_Neuron`: A Neuron in the graph, should be the output Neuron (have no outgoing edges).\n",
    "        `sorted_neurons`: a topologically sorted list of neurons.\n",
    "\n",
    "    Returns the output Neuron's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_neurons:\n",
    "        n.forward()\n",
    "\n",
    "    return output_Neuron.value\n",
    "\n",
    "\n",
    "x, y, z = Input(), Input(), Input()\n",
    "inputs = [x, y, z]\n",
    "\n",
    "weight_x, weight_y, weight_z = Input(), Input(), Input()\n",
    "weights = [weight_x, weight_y, weight_z]\n",
    "\n",
    "bias = Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "\n",
    "feed_dict = {\n",
    "\tx: 6,\n",
    "\ty: 14,\n",
    "\tz: 3,\n",
    "\tweight_x: 0.5,\n",
    "\tweight_y: 0.25,\n",
    "\tweight_z: 1.4,\n",
    "\tbias: 2\n",
    "}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "print(output) # should be 12.7 with this example\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modify Linear#forward so that it linearly transforms\n",
    "input matrices, weights matrices and a bias vector to\n",
    "an output.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        self.inbound_layers = inbound_layers\n",
    "        self.value = None\n",
    "        self.outbound_layers = []\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    While it may be strange to consider an input a layer when\n",
    "    an input is only an individual node in a layer, for the sake\n",
    "    of simpler code we'll still use Layer as the base class.\n",
    "    \n",
    "    Think of Input as collating many individual input nodes into\n",
    "    a Layer.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # An Input layer has no inbound layers,\n",
    "        # so no need to pass anything to the Layer instantiator\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, inbound_layer, weights, bias):\n",
    "        # Notice the ordering of the input layers passed to the\n",
    "        # Layer constructor.\n",
    "        Layer.__init__(self, [inbound_layer, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this layer to the linear transform output.\n",
    "        \n",
    "        Your code goes here!\n",
    "        \"\"\"\n",
    "        self.value = (np.dot(self.inbound_layers[0].value,self.inbound_layers[1].value)) + self.inbound_layers[2].value\n",
    "            \n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_layer, sorted_layers):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_layer`: A Layer in the graph, should be the output layer (have no outgoing edges).\n",
    "        `sorted_layers`: a topologically sorted list of layers.\n",
    "\n",
    "    Returns the output layer's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_layers:\n",
    "        n.forward()\n",
    "\n",
    "    return output_layer.value\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "\n",
    "x = np.array([[-1., -2.], [-1, -2]])   # each row is an observation here \n",
    "w = np.array([[2., -3], [2., -3]])     # each column is a node , # of rows is same as dimension of each input \n",
    "b = np.array([-3., -5])                # the size of bias is the size of nodes \n",
    "\n",
    "feed_dict = {inputs: x, weights: w, bias: b}   # this line also assigns values to input layers \n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(f, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[-9., 4.],\n",
    "[-9., 4.]]\n",
    "\"\"\"\n",
    "inputs.value\n",
    "weights.value\n",
    "inputs.value\n",
    "f.inbound_layers[0]\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fix the Sigmoid class so that it computes the sigmoid function\n",
    "on the forward pass!\n",
    "\n",
    "Scroll down to get started.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "#         print(inbound_layers[0])\n",
    "        self.inbound_layers = inbound_layers  # is a list , can be a list of input layers like biase, weight, linear,etc\n",
    "        self.value = None\n",
    "        self.outbound_layers = []\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward():\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    def __init__(self):\n",
    "        # An Input layer has no inbound layers,\n",
    "        # so no need to pass anything to the Layer instantiator\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        # An Input Layer has no inputs so we refer to ourself\n",
    "        # for the gradient\n",
    "        self.gradients = {self: 0}\n",
    "        for n in self.outbound_Layers:\n",
    "            self.gradients[self] += n.gradients[self]\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, inbound_layer, weights, bias):\n",
    "        # Notice the ordering of the input layers passed to the\n",
    "        # Layer constructor.\n",
    "        Layer.__init__(self, [inbound_layer, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inbound_layers[0].value\n",
    "        weights = self.inbound_layers[1].value\n",
    "        bias = self.inbound_layers[2].value\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    You need to fix the `_sigmoid` and `forward` methods.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "\n",
    "        Return the result of the sigmoid function.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "#         print(x.value)\n",
    "        return np.exp(x)/(1+np.exp(x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Set the value of this layer to the result of the\n",
    "        sigmoid function, `_sigmoid`.\n",
    "        \n",
    "        Your code here!\n",
    "        \"\"\"\n",
    "        # This is a dummy value to prevent numpy errors\n",
    "        # if you test without changing this method.\n",
    "#         self.value = -1\n",
    "        self.value = self._sigmoid(self.inbound_layers[0].value)\n",
    "#         for n in self.inbound_layers:\n",
    "#             print(n.value)\n",
    "#             self.value = self._sigmoid(n.value)\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers. \n",
    "    \n",
    "    Amir : it seems it takes care of the assignment of those values to the layers too ! \n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):  # assigning value to the layer?\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(output_layer, sorted_layers):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `output_layer`: A Layer in the graph, should be the output layer (have no outgoing edges).\n",
    "        `sorted_layers`: a topologically sorted list of layers.\n",
    "\n",
    "    Returns the output layer's value\n",
    "    \"\"\"\n",
    "\n",
    "    for n in sorted_layers:\n",
    "        n.forward()\n",
    "\n",
    "    return output_layer.value\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This network feeds the output of a linear transform\n",
    "to the sigmoid function.\n",
    "\n",
    "Finish implementing the Sigmoid class in miniflow.py!\n",
    "\n",
    "Feel free to play around with this network, too!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "inputs, weights, bias = Input(), Input(), Input()\n",
    "\n",
    "f = Linear(inputs, weights, bias)\n",
    "g = Sigmoid(f)\n",
    "\n",
    "x = np.array([[-1., -2.], [-1, -2]])\n",
    "w = np.array([[2., -3], [2., -3]])\n",
    "b = np.array([-3., -5])\n",
    "\n",
    "feed_dict = {inputs: x, weights: w, bias: b}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "output = forward_pass(g, graph)\n",
    "\n",
    "\"\"\"\n",
    "Output should be:\n",
    "[[  1.23394576e-04   9.82013790e-01]\n",
    " [  1.23394576e-04   9.82013790e-01]]\n",
    "\"\"\"\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Base class for layers in the network.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `inbound_layers`: A list of layers with edges into this layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        \"\"\"\n",
    "        Layer's constructor (runs when the object is instantiated). Sets\n",
    "        properties that all layers need.\n",
    "        \"\"\"\n",
    "        # A list of layers with edges into this layer.\n",
    "        self.inbound_layers = inbound_layers\n",
    "        # The eventual value of this layer. Set by running\n",
    "        # the forward() method.\n",
    "        self.value = None\n",
    "        # A list of layers that this layer outputs to.\n",
    "        self.outbound_layers = []\n",
    "        # Sets this layer as an outbound layer for all of\n",
    "        # this layer's inputs.\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        \"\"\"\n",
    "        Every layer that uses this class as a base class will\n",
    "        need to define its own `forward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    A generic input into the network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # The base class constructor has to run to set all\n",
    "        # the properties here.\n",
    "        #\n",
    "        # The most important property on an Input is value.\n",
    "        # self.value is set during `topological_sort` later.\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs a linear transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, W, b):\n",
    "        # The base class (Layer) constructor. Weights and bias\n",
    "        # are treated like inbound layers.\n",
    "        Layer.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Performs the math behind a linear transform.\n",
    "        \"\"\"\n",
    "        X = self.inbound_layers[0].value\n",
    "        W = self.inbound_layers[1].value\n",
    "        b = self.inbound_layers[2].value\n",
    "        self.value = np.dot(X, W) + b\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs the sigmoid activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        # The base class constructor.\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Perform the sigmoid function and set the value.\n",
    "        \"\"\"\n",
    "        input_value = self.inbound_layers[0].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "\n",
    "\n",
    "class MSE(Layer):\n",
    "    def __init__(self, y, a):\n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last layer for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Layer.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_layers[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_layers[1].value.reshape(-1, 1)\n",
    "        self.value = np.square(y - a).mean()\n",
    "        # TODO: your code here\n",
    "#         pass\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_pass(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Test your MSE method with this script!\n",
    "\n",
    "No changes necessary, but feel free to play\n",
    "with this script to test your network.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "y, a = Input(), Input()\n",
    "cost = MSE(y, a) \n",
    "\n",
    "y_ = np.array([1, 2, 3])\n",
    "a_ = np.array([4.5, 5, 10])\n",
    "\n",
    "feed_dict = {y: y_, a: a_}\n",
    "graph = topological_sort(feed_dict)\n",
    "# forward pass\n",
    "forward_pass(graph)\n",
    "\n",
    "\"\"\"\n",
    "Expected output\n",
    "\n",
    "23.4166666667\n",
    "\"\"\"\n",
    "print(cost.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Given the starting point of any `x` gradient descent\n",
    "should be able to find the minimum value of x for the\n",
    "cost function `f` defined below.\n",
    "\"\"\"\n",
    "import random\n",
    "# from gd import gradient_descent_update\n",
    "\n",
    "def gradient_descent_update(x, gradx, learning_rate):\n",
    "    \"\"\"\n",
    "    Performs a gradient descent update.\n",
    "    \"\"\"\n",
    "    # TODO: Implement gradient descent.\n",
    "    \n",
    "    # Return the new value for x\n",
    "    return (x - learning_rate*gradx) \n",
    "\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Quadratic function.\n",
    "\n",
    "    It's easy to see the minimum value of the function\n",
    "    is 5 when is x=0.\n",
    "    \"\"\"\n",
    "    return x**2 + 20*x + 5   \n",
    "\n",
    "    # imagine in MSE, sum(ax - y)^2 after some algebra become f(x,y)a^2 + g(x,y)a + w(x,y)\n",
    "    # where all functions of x,y are numeric and known (based on training data), and you re minimizes \n",
    "    # the function to find a. in this example a = x (the notation is confusing)\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    \"\"\"\n",
    "    Derivative of `f` with respect to `x`.\n",
    "    \"\"\"\n",
    "    return 2*x + 20\n",
    "###  the unkown parameter we are optimizing for is x  ### \n",
    "\n",
    "# We generate a single random number between 0 and 10000\n",
    "x = random.randint(0, 10000)\n",
    "# TODO: Set the learning rate\n",
    "learning_rate = 0.075\n",
    "epochs = 5\n",
    "for i in range(epochs+1):\n",
    "    cost = f(x)   # calculate the function as point x \n",
    "    gradx = df(x)  # calculate grad(x) at point x\n",
    "    print(\"EPOCH {}: f(x)  = {:.3f}, grad = {:.3f}, x = {:.3f}\".format(i, cost, gradx,x))\n",
    "#     print(- gradx * learning_rate)\n",
    "    x = gradient_descent_update(x, gradx, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"\n",
    "    Base class for layers in the network.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `inbound_layers`: A list of layers with edges into this layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, inbound_layers=[]):\n",
    "        \"\"\"\n",
    "        Layer's constructor (runs when the object is instantiated). Sets\n",
    "        properties that all layers need.\n",
    "        \"\"\"\n",
    "        # A list of layers with edges into this layer.\n",
    "        self.inbound_layers = inbound_layers\n",
    "        # The eventual value of this layer. Set by running\n",
    "        # the forward() method.\n",
    "        self.value = None\n",
    "        # A list of layers that this layer outputs to.\n",
    "        self.outbound_layers = []\n",
    "        # New property! Keys are the inputs to this layer and\n",
    "        # their values are the partials of this layer with\n",
    "        # respect to that input.\n",
    "        self.gradients = {}\n",
    "        # Sets this layer as an outbound layer for all of\n",
    "        # this layer's inputs.\n",
    "        for layer in inbound_layers:\n",
    "            layer.outbound_layers.append(self)\n",
    "\n",
    "    def forward():\n",
    "        \"\"\"\n",
    "        Every layer that uses this class as a base class will\n",
    "        need to define its own `forward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward():\n",
    "        \"\"\"\n",
    "        Every layer that uses this class as a base class will\n",
    "        need to define its own `backward` method.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Input(Layer):\n",
    "    \"\"\"\n",
    "    A generic input into the network.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # The base class constructor has to run to set all\n",
    "        # the properties here.\n",
    "        #\n",
    "        # The most important property on an Input is value.\n",
    "        # self.value is set during `topological_sort` later.\n",
    "        Layer.__init__(self)\n",
    "\n",
    "    def forward(self):\n",
    "        # Do nothing because nothing is calculated.\n",
    "        pass\n",
    "\n",
    "    def backward(self):\n",
    "        # An Input layer has no inputs so the gradient (derivative)\n",
    "        # is zero.\n",
    "        # The key, `self`, is reference to this object.\n",
    "        self.gradients = {self: 0}\n",
    "        # Weights and bias may be inputs, so you need to sum\n",
    "        # the gradient from output gradients.\n",
    "        for n in self.outbound_layers:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] += grad_cost * 1\n",
    "\n",
    "\n",
    "class Linear(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs a linear transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, W, b):\n",
    "        # The base class (Layer) constructor. Weights and bias\n",
    "        # are treated like inbound layers.\n",
    "        Layer.__init__(self, [X, W, b])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Performs the math behind a linear transform.\n",
    "        \"\"\"\n",
    "        X = self.inbound_layers[0].value\n",
    "        W = self.inbound_layers[1].value\n",
    "        b = self.inbound_layers[2].value\n",
    "        self.value = np.dot(X, W) + b\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient based on the output values.\n",
    "        \"\"\"\n",
    "#         f = XW + b\n",
    "#         df/dX = W\n",
    "\n",
    "        # Initialize a partial for each of the inbound_layers.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inbound_layers}\n",
    "        # Cycle through the outputs. The gradient will change depending\n",
    "        # on each output, so the gradients are summed over all outputs.\n",
    "        for n in self.outbound_layers:\n",
    "            # Get the partial of the cost with respect to this layer.\n",
    "            grad_cost = n.gradients[self]\n",
    "            # Set the partial of the loss with respect to this layer's inputs.\n",
    "            self.gradients[self.inbound_layers[0]] += np.dot(grad_cost, self.inbound_layers[1].value.T)\n",
    "            # Set the partial of the loss with respect to this layer's weights.\n",
    "            self.gradients[self.inbound_layers[1]] += np.dot(self.inbound_layers[0].value.T, grad_cost)\n",
    "            # Set the partial of the loss with respect to this layer's bias.\n",
    "            self.gradients[self.inbound_layers[2]] += np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "\n",
    "class Sigmoid(Layer):\n",
    "    \"\"\"\n",
    "    Represents a layer that performs the sigmoid activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, layer):\n",
    "        # The base class constructor.\n",
    "        Layer.__init__(self, [layer])\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "        \"\"\"\n",
    "        return 1. / (1. + np.exp(-x))\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Perform the sigmoid function and set the value.\n",
    "        \"\"\"\n",
    "        input_value = self.inbound_layers[0].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient using the derivative of\n",
    "        the sigmoid function.\n",
    "        \"\"\"\n",
    "        # Initialize the gradients to 0.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inbound_layers}\n",
    "        \n",
    "        # Cycle through the outputs. The gradient will change depending\n",
    "        # on each output, so the gradients are summed over all outputs.\n",
    "        for n in self.outbound_layers:\n",
    "            # Get the partial of the cost with respect to this layer.\n",
    "            grad_cost = n.gradients[self]\n",
    "            \"\"\"\n",
    "            TODO: Your code goes here!\n",
    "            \n",
    "            Set the gradients property to the gradients with respect to each input.\n",
    "            \n",
    "            NOTE: See the Linear layer and MSE layer for examples.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "class MSE(Layer):\n",
    "    def __init__(self, y, a):  # inbound layers are y and a \n",
    "        \"\"\"\n",
    "        The mean squared error cost function.\n",
    "        Should be used as the last layer for a network.\n",
    "        \"\"\"\n",
    "        # Call the base class' constructor.\n",
    "        Layer.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        Calculates the mean squared error.\n",
    "        \"\"\"\n",
    "        # NOTE: We reshape these to avoid possible matrix/vector broadcast\n",
    "        # errors.\n",
    "        #\n",
    "        # For example, if we subtract an array of shape (3,) from an array of shape\n",
    "        # (3,1) we get an array of shape(3,3) as the result when we want\n",
    "        # an array of shape (3,1) instead.\n",
    "        #\n",
    "        # Making both arrays (3,1) insures the result is (3,1) and does\n",
    "        # an elementwise subtraction as expected.\n",
    "        y = self.inbound_layers[0].value.reshape(-1, 1)\n",
    "        a = self.inbound_layers[1].value.reshape(-1, 1)\n",
    "\n",
    "        self.m = self.inbound_layers[0].value.shape[0]\n",
    "        \n",
    "        # Save the computed output for backward.\n",
    "        self.diff = y - a\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"\n",
    "        Calculates the gradient of the cost.\n",
    "        \n",
    "        This is the final layer of the network so outbound layers\n",
    "        are not a concern.\n",
    "        MSE = sum(y - a)^ 2\n",
    "        dMSE/dy = 2 sum(y-a)\n",
    "        dMSE/da =-2 sum(y-a)\n",
    "        \"\"\"\n",
    "        self.gradients[self.inbound_layers[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inbound_layers[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "\n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort the layers in topological order using Kahn's Algorithm.\n",
    "\n",
    "    `feed_dict`: A dictionary where the key is a `Input` Layer and the value is the respective value feed to that Layer.\n",
    "\n",
    "    Returns a list of sorted layers.\n",
    "    \"\"\"\n",
    "\n",
    "    input_layers = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    layers = [n for n in input_layers]\n",
    "    while len(layers) > 0:\n",
    "        n = layers.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outbound_layers:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            layers.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_layers)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outbound_layers:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "def forward_and_backward(graph):\n",
    "    \"\"\"\n",
    "    Performs a forward pass and a backward pass through a list of sorted Layers.\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "        `graph`: The result of calling `topological_sort`.\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "\n",
    "    # Backward pass\n",
    "    # see: https://docs.python.org/2.3/whatsnew/section-slices.html\n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "Test your network here!\n",
    "\n",
    "No need to change this code, but feel free to tweak it\n",
    "to test your network!\n",
    "\n",
    "Make your changes to backward method of the Sigmoid class in miniflow.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "# from miniflow import *\n",
    "\n",
    "X, W, b = Input(), Input(), Input()\n",
    "y = Input()\n",
    "f = Linear(X, W, b)\n",
    "a = Sigmoid(f)\n",
    "cost = MSE(y, a)\n",
    "\n",
    "X_ = np.array([[-1., -2.], [-1, -2]])\n",
    "W_ = np.array([[2.], [3.]])\n",
    "b_ = np.array([-3.])\n",
    "y_ = np.array([1, 2])\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W: W_,\n",
    "    b: b_,\n",
    "}\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "forward_and_backward(graph)\n",
    "# return the gradients for each Input\n",
    "gradients = [t.gradients[t] for t in [X, y, W, b]]\n",
    "\n",
    "\"\"\"\n",
    "Expected output\n",
    "\n",
    "[array([[ -3.34017280e-05,  -5.01025919e-05],\n",
    "       [ -6.68040138e-05,  -1.00206021e-04]]), array([[ 0.9999833],\n",
    "       [ 1.9999833]]), array([[  5.01028709e-05],\n",
    "       [  1.00205742e-04]]), array([ -5.01028709e-05])]\n",
    "\"\"\"\n",
    "print(gradients)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "# config = tf.ConfigProto(allow_soft_placement = True)\n",
    "# sess = tf.Session(config = config)\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "\n",
    "c = tf.matmul(a, b)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'b_2': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:1\"]()]]\n\nCaused by op 'b_2', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-e9e0d44150fb>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b_2': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:1\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b_2': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:1\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-02c98d39c9a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Runs the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b_2': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:1\"]()]]\n\nCaused by op 'b_2', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-e9e0d44150fb>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b_2': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b_2 = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:1\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0efdea91c8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Run the tf.constant operation in the session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello_constant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create TensorFlow object called hello_constant\n",
    "hello_constant = tf.constant('Hello World!')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the tf.constant operation in the session\n",
    "    output = sess.run(hello_constant)\n",
    "    print(output)\n",
    "    \n",
    "# A is a 0-dimensional int32 tensor\n",
    "A = tf.constant(1234) \n",
    "# B is a 1-dimensional int32 tensor\n",
    "B = tf.constant([ [123,456,789] ]) \n",
    " # C is a 2-dimensional int32 tensor\n",
    "C = tf.constant([ [123,456,789], [222,333,444] ])\n",
    "\n",
    "x = tf.placeholder(tf.string)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Hello World'})   \n",
    "    # when you run all variables or constants should have a value assined to them \n",
    "    \n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.placeholder(tf.int32)\n",
    "z = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(x, feed_dict={x: 'Test String', y: 123, z: 45.67})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    x = tf.placeholder(tf.int32)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed the x tensor 123\n",
    "        output = sess.run(x, feed_dict = {x : 123})\n",
    "\n",
    "    return output\n",
    "run()\n",
    "\n",
    "x = tf.add(5, 2)\n",
    "x = tf.sub(10, 4)\n",
    "y = tf.mul(2, 5) \n",
    "with tf.Session() as sess:\n",
    "    sess.run(y)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# TODO: Convert the following to TensorFlow:\n",
    "x = tf.constant(10)\n",
    "y = tf.constant(2)\n",
    "z = tf.sub(tf.div(x,y) , tf.constant(1))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(z)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6dfd905f65f9>:2 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6dfd905f65f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(5)\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "n_features = 120\n",
    "n_labels = 5\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "\n",
    "\n",
    "n_labels = 5\n",
    "bias = tf.Variable(tf.zeros(n_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of w <class 'tensorflow.python.ops.variables.Variable'>\n",
      "type of logit <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "shape of 1 label (10,)\n",
      "shape of 1 train features sample (784,)\n",
      "WARNING:tensorflow:From <ipython-input-4-aaee1d7dedf6>:89 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aaee1d7dedf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# TODO: Initialize session variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"sandbox_solution.py\" tab\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# from quiz import weights, biases, linear\n",
    "# Solution is available in the other \"quiz_solution.py\" tab\n",
    "\n",
    "\n",
    "def weights(n_features, n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow weights\n",
    "    :param n_features: Number of features\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow weights\n",
    "    \"\"\"\n",
    "    return tf.Variable(tf.truncated_normal((n_features, n_labels)))\n",
    "    \n",
    "\n",
    "\n",
    "def biases(n_labels):\n",
    "    \"\"\"\n",
    "    Return TensorFlow bias\n",
    "    :param n_labels: Number of labels\n",
    "    :return: TensorFlow bias\n",
    "    \"\"\"\n",
    "    # TODO: Return biases\n",
    "    return tf.Variable(tf.zeros(n_labels))\n",
    "\n",
    "\n",
    "def linear(input, w, b):\n",
    "    \"\"\"\n",
    "    Return linear function in TensorFlow\n",
    "    :param input: TensorFlow input\n",
    "    :param w: TensorFlow weights\n",
    "    :param b: TensorFlow biases\n",
    "    :return: TensorFlow linear function\n",
    "    \"\"\"\n",
    "    # TODO: Linear Function (xW + b)\n",
    "    return tf.add(tf.matmul(input,w) , b)\n",
    "\n",
    "def mnist_features_labels(n_labels):\n",
    "    \"\"\"\n",
    "    Gets the first <n> labels from the MNIST dataset\n",
    "    :param n_labels: Number of labels to use\n",
    "    :return: Tuple of feature list and label list\n",
    "    \"\"\"\n",
    "    mnist_features = []\n",
    "    mnist_labels = []\n",
    "\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "#     mnist = input_data.read_data_sets('/datasets/ud730/mnist', one_hot=True)\n",
    "\n",
    "    # In order to make quizzes run faster, we're only looking at 10000 images\n",
    "    for mnist_feature, mnist_label in zip(*mnist.train.next_batch(1000)):\n",
    "\n",
    "        # Add features and labels if it's for the first <n>th labels\n",
    "        if mnist_label[:n_labels].any():\n",
    "            mnist_features.append(mnist_feature)\n",
    "            mnist_labels.append(mnist_label[:n_labels])\n",
    "\n",
    "    return mnist_features, mnist_labels\n",
    "\n",
    "\n",
    "# Number of features (28*28 image is 784 features)\n",
    "n_features = 784\n",
    "# Number of labels\n",
    "n_labels = 10\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32)\n",
    "labels = tf.placeholder(tf.float32)\n",
    "\n",
    "# Weights and Biases\n",
    "w = weights(n_features, n_labels)\n",
    "b = biases(n_labels)\n",
    "print('type of w',type(w))\n",
    "# Linear Function xW + b\n",
    "logits = linear(features, w, b)\n",
    "print('type of logit',type(logits))\n",
    "# Training data\n",
    "# train feature is a list of (784,) shape\n",
    "# train feature is a list of (10,) shape\n",
    "train_features, train_labels = mnist_features_labels(n_labels)\n",
    "\n",
    "print('shape of 1 label', train_labels[0].shape)\n",
    "print('shape of 1 train features sample', train_features[0].shape)\n",
    "with tf.Session() as session:\n",
    "    # TODO: Initialize session variables\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "\n",
    "    # Cross entropy\n",
    "    # This quantifies how far off the predictions were.\n",
    "    # You'll learn more about this in future lessons.\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)\n",
    "\n",
    "    # Training loss\n",
    "    # You'll learn more about this in future lessons.\n",
    "    loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # Rate at which the weights are changed\n",
    "    # You'll learn more about this in future lessons.\n",
    "    learning_rate = 0.08\n",
    "\n",
    "    # Gradient Descent\n",
    "    # This is the method used to train the model\n",
    "    # You'll learn more about this in future lessons.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Run optimizer and get loss\n",
    "    # runs two things optimizer and loss ? \n",
    "    _, l = session.run(\n",
    "        [optimizer, loss],\n",
    "        feed_dict={features: train_features, labels: train_labels})\n",
    "\n",
    "# Print loss\n",
    "print('Loss: {}'.format(l))\n",
    "print('parameters: {}'.format(w.value()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "logits = [3.0, 1.0, 0.2]\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def run():\n",
    "    output = None\n",
    "    logit_data = [2.0, 1.0, 0.1]\n",
    "    logits = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # TODO: Calculate the softmax of the logits\n",
    "    softmax = tf.nn.softmax(logits)    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # TODO: Feed in the logit data\n",
    "        output = sess.run(softmax, feed_dict = {logits : logit_data}   )\n",
    "\n",
    "    return output\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow as tf\n",
    "\n",
    "softmax_data = [0.7, 0.2, 0.1]\n",
    "one_hot_data = [1.0, 0.0, 0.0]\n",
    "\n",
    "softmax = tf.placeholder(tf.float32)\n",
    "one_hot = tf.placeholder(tf.float32)\n",
    "cross = -tf.reduce_sum(tf.mul(tf.log(softmax),one_hot))\n",
    "# TODO: Print cross entropy from session\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(cross, feed_dict = {softmax : softmax_data, one_hot : one_hot_data}   )\n",
    "    print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def batches(batch_size, features, labels):\n",
    "    \"\"\"\n",
    "    Create batches of features and labels\n",
    "    :param batch_size: The batch size\n",
    "    :param features: List of features\n",
    "    :param labels: List of labels\n",
    "    :return: Batches of (Features, Labels)\n",
    "    \"\"\"\n",
    "    assert len(features) == len(labels)\n",
    "    # TODO: Implement batching\n",
    "    outout_batches = []\n",
    "    # notice in python if A = [1,2,3]\n",
    "    # and you say A[0:10] = [1,2,3] it wont yell at you !\n",
    "    sample_size = len(features)\n",
    "    for start_i in range(0, sample_size, batch_size):\n",
    "        end_i = start_i + batch_size\n",
    "        batch = [features[start_i:end_i], labels[start_i:end_i]]\n",
    "        outout_batches.append(batch)\n",
    "        \n",
    "    return outout_batches\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# from quiz import batches\n",
    "from pprint import pprint\n",
    "\n",
    "# 4 Samples of features\n",
    "example_features = [\n",
    "    ['F11','F12','F13','F14'],\n",
    "    ['F21','F22','F23','F24'],\n",
    "    ['F31','F32','F33','F34'],\n",
    "    ['F41','F42','F43','F44']]\n",
    "# 4 Samples of labels\n",
    "example_labels = [\n",
    "    ['L11','L12'],\n",
    "    ['L21','L22'],\n",
    "    ['L31','L32'],\n",
    "    ['L41','L42']]\n",
    "\n",
    "# PPrint prints data structures like 2d arrays, so they are easier to read\n",
    "pprint(batches(3, example_features, example_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_count = 784\n",
    "labels_count = 10\n",
    "\n",
    "# TODO: Set the features and labels tensors\n",
    "features = tf.placeholder(tf.float32,[None,features_count])\n",
    "labels = tf.placeholder(tf.float32,[None,labels_count])\n",
    "\n",
    "# TODO: Set the weights and biases tensors\n",
    "weights = tf.Variable(tf.truncated_normal((features_count,labels_count)))\n",
    "biases = tf.Variable(tf.zeros(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_layer = tf.add(tf.matmul(features, weights), biases)\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "output = tf.add(tf.matmul(hidden_layer, weights), biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz Solution\n",
    "# Note: You can't run code in this tab\n",
    "import tensorflow as tf\n",
    "\n",
    "output = None\n",
    "# would have had 3 classes (output) if by itself , each class has 4 features \n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "# two classes output \n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input  3 observation each 4 feature \n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "hidden_layer1 = tf.add(tf.matmul(features, weights[0]), biases[0])   #(3x4)(4x3) + 3 = 3x3 output\n",
    "hidden_layer2 = tf.nn.relu(hidden_layer1)    #  output is also (3x3) all negatives become 0\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])  # (3x3)(3x2) + 2 = (3x2)   \n",
    "soft = tf.nn.softmax(logits,dim=0)   # if you want two classes then use dim= 0 else use dim = -1 default \n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())  \n",
    "    print(sess.run(hidden_layer1))\n",
    "    print(sess.run(hidden_layer2))\n",
    "    print(sess.run(logits))\n",
    "    print(sess.run(soft))\n",
    "    A = sess.run(soft)\n",
    "A.sum(axis = 0)  # output of softmax is for 2 class ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Network in TensorFlow\n",
    "You've seen how to build a logistic classifier using TensorFlow. Now you're going to see how to use the logistic classifier to build a deep neural network.\n",
    "\n",
    "Step by Step\n",
    "In the following walkthrough, we'll step through TensorFlow code written to classify the letters in the MNIST database. If you would like to run the network on your computer, the file is provided here. You can find this and many more examples of TensorFlow at Aymeric Damien's GitHub repository.\n",
    "\n",
    "Code\n",
    "TensorFlow MNIST\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "You'll use the MNIST dataset provided by TensorFlow, which batches and One-Hot encodes the data for you.\n",
    "\n",
    "Learning Parameters\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "The focus here is on the architecture of multilayer neural networks, not parameter tuning, so here we'll just give you the learning parameters.\n",
    "\n",
    "Hidden Layer Parameters\n",
    "n_hidden_layer = 256 # layer number of features\n",
    "The variable n_hidden_layer determine the size of the hidden layer in the neural network. This is also know as the width of a layer.\n",
    "\n",
    "Weights and Biases\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "Deep neural networks use multiple layers with each layer requiring it's own weight and bias. The 'hidden_layer' weight and bias is for the hidden layer. The 'out' weight and bias is for the output layer. If the neural network were deeper, there would be weights and biases for each additional layer.\n",
    "\n",
    "Input\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "The MNIST data is made up of 28px by 28px images with a single channel. The tf.reshape() function above reshapes the 28px by 28px matrices in x into vectors of 784px by 1px.\n",
    "\n",
    "Multilayer Perceptron\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])\n",
    "You've seen the linear function tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer']) before, also known as xw + b. Combining linear functions together using a ReLU will give you a two layer network.\n",
    "\n",
    "Optimizer\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "This is the same optimization technique used in the Intro to TensorFLow lab.\n",
    "\n",
    "Session\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "The MNIST library in TensorFlow provides the ability to receive the dataset in batches. Calling the mnist.train.next_batch() function returns a subset of the training data.\n",
    "\n",
    "Deeper Neural Network\n",
    "\n",
    "That's it! Going from one layer to two is easy. Adding more layers to the network allows you to solve more complicated problems. In the next video, you'll see how changing the number of layers can affect your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you construct the graph and its operations first , the optimize ! \n",
    "# it is like spark with lazy operations ! \n",
    "\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "n_hidden_layer = 256\n",
    "\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_layer, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "x_flat = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_flat, weights['hidden_layer']), biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_1, weights['out']), biases['out'])\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model \n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = 'model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# load the model \n",
    "\n",
    "\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = 'model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "# Quiz 2\n",
    "# Apply dropout to the code from the ReLU Quiz. Use the keep_prob placeholder to pass in a probability of 0.5.\n",
    "\n",
    "# Note: Output will be different every time the code is run. This is caused by dropout randomizing the units it drops.\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)  # not a variable so it is not initiated with the first call in run \n",
    "# Input\n",
    "features = tf.Variable([[0.0, 2.0, 3.0, 4.0], [0.1, 0.2, 0.3, 0.4], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model with Dropout\n",
    "hiddenLayer1 = tf.add(tf.matmul(features,weights[0]),biases[0])\n",
    "hiddenLayer2 = tf.nn.relu(hiddenLayer1)\n",
    "hiddenLayer3 = tf.nn.dropout(hiddenLayer2,keep_prob)  # drop out has its own layer !\n",
    "logits = tf.add(tf.matmul(hiddenLayer3,weights[1]),biases[1])\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(logits,feed_dict={keep_prob:0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Dimensionality\n",
    "From what we've learned so far, how can we calculate the number of neurons of each layer in our CNN?\n",
    "Given our input layer has a volume of W, our filter has a volume (height x width x depth) of F, we have a stride of S, and a padding of P, the following formula gives us the volume of the next layer: (W−F+2P)/S+1.\n",
    "\n",
    "Knowing the dimensionality of each additional layer helps us understand how large our model is and how our decisions around filter size and stride affect the size of our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "H = height, W = width, D = depth\n",
    "\n",
    "We have an input of shape 32x32x3 (HxWxD)\n",
    "20 filters of shape 8x8x3 (HxWxD)  - this is like 8x8x3x20 \n",
    "so an image patch of (1,8x8x3) is multiplied by a filter of (8x8x3,20) = which gives you a column vector of length 20 (depth of output)\n",
    "for each application of filter. Now you just need to calculate how many times you can apply the filter to the image\n",
    "considering padding and sride to get the height and width of the output too. \n",
    "A stride of 2 for both the height and width (S)\n",
    "Valid padding of size 1 (P)\n",
    "\n",
    "\n",
    "Recall the formula for calculating the new height or width:\n",
    "\n",
    "new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "Convolutional Layer Output Shape\n",
    "What's the shape of the output?\n",
    "\n",
    "remember the number of times you can run filter on the image (32 - 8 + 1) without padding and stride \n",
    "if you add pad you are essentially increasing the dimension of image from each end of the image\n",
    "(32 + 2p - 8 + 1), this happens in both directions x and y , when you stride number of times reduces\n",
    "(32 + 2p - 8)/S + 1 ... round down the ratio \n",
    "\n",
    "The answer format is HxWxD, so if you think the new height is 9, new width is 9, and new depth is 5, then type 9x9x5.\n",
    "14x14x20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "filter_weights = tf.Variable(tf.truncated_normal((8, 8, 3, 20))) # (height, width, input_depth, output_depth)\n",
    "filter_bias = tf.Variable(tf.zeros(20))\n",
    "strides = [1, 2, 2, 1] # (batch, height, width, depth)\n",
    "padding = 'VALID'\n",
    "conv = tf.nn.conv2d(input, filter_weights, strides, padding) + filter_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if Weights are not being shared, we have a different weight for each filter everytime we apply filter\n",
    "14*14 times the 20 filters are applied to the image --- each filter having 8x8x3 parameters + 1 bias (each filter is a neuron with its own bias) , there are 20 of them\n",
    "14*14*(8x8x3+1)*20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one of the convolutional neural nets lectures we had: \n",
    "Setup\n",
    "H = height, W = width, D = depth\n",
    "We have an input of shape 32x32x3 (HxWxD)\n",
    "20 filters of shape 8x8x3 (HxWxD)\n",
    "A stride of 2 for both the height and width (S)\n",
    "Zero padding of size 1 (P)\n",
    "Output Layer\n",
    "14x14x20 (HxWxD)\n",
    "\n",
    "Here is how i see things: \n",
    "for each of the 20 filters, we have (8x8x3) scalar weights + 1 bias \n",
    "Each patch of size (8x8x3) from the image (if flatten, it becomes a vector of size (8x8x3)) is multiplied by filter of size (8x8x3) and the result of the dot product of these two vectors is a single value. We then add a bias to this single value. The result of applying this single filter to a patch of size 8x8x3 from the image is a single scalar. \n",
    "We apply the procedure above 20 times for each filter to the same patch of the image, and you get a vector of length 20.\n",
    "There are 14x14 of such patches of size (8x8x3) in the image based on padding and stride size specified in the setup.\n",
    "Can somebody tell me if my understanding is correct. Also i am not sure if i understand the concept \"Neuron\". What is a neuron in this case ? Why do you call it a neuron ? how many of them are there ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 100\n",
    "image_height = 100\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_width, image_height, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_width, filter_size_height, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer1 = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer2 = tf.nn.bias_add(conv_layer1, bias)\n",
    "# Apply activation function\n",
    "conv_layer3 = tf.nn.relu(conv_layer2)\n",
    "\n",
    "# max pooling \n",
    "# has the same formula as filter with no padding of course !\n",
    "\n",
    "# new_height = (input_height - filter_height)/S + 1\n",
    "# new_width = (input_width - filter_width)/S + 1\n",
    "# Apply Max Pooling\n",
    "# The ksize and strides parameters are structured as 4-element lists, with each element\n",
    "# corresponding to a dimension of the input tensor ([batch, height, width, channels]).\n",
    "# For both ksize and strides, the batch and channel dimensions are typically set to 1.\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer3,\n",
    "    ksize=[1, 2, 2, 1],  # the size of the pixels to consider for max pooling, you lose data with bigger values \n",
    "    strides=[1, 2, 2, 1],  # you can apply strides like you use it for filters stride 2 cuts image in half \n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d05dd363f8ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfilter_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'VALID'\u001b[0m \u001b[0;31m# output dimension is independent of padding changing to 'SAME' does not change things\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "input = tf.placeholder(tf.float32, (None, 4, 4, 5))\n",
    "filter_shape = [1, 2, 2, 1]\n",
    "strides = [1, 2, 2, 1]\n",
    "padding = 'VALID' # output dimension is independent of padding changing to 'SAME' does not change things \n",
    "pool = tf.nn.max_pool(input, filter_shape, strides, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-0.12.0rc1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/pemfir/.local/lib/python3.5/site-packages (from tensorflow)\n",
      "Collecting protobuf==3.1.0 (from tensorflow)\n",
      "  Using cached protobuf-3.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26 in /home/pemfir/.local/lib/python3.5/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/pemfir/.local/lib/python3.5/site-packages (from tensorflow)\n",
      "Requirement already satisfied: setuptools in /home/pemfir/.local/lib/python3.5/site-packages (from protobuf==3.1.0->tensorflow)\n",
      "Installing collected packages: protobuf, tensorflow\n",
      "  Found existing installation: protobuf 3.0.0\n",
      "    Uninstalling protobuf-3.0.0:\n",
      "      Successfully uninstalled protobuf-3.0.0\n",
      "Successfully installed protobuf-3.1.0 tensorflow-0.12.0rc1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-5-547c3b772df7>:99 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    998\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1047\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[0;32m-> 1048\u001b[0;31m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1049\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-547c3b772df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Launch the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Training cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n\nCaused by op 'b', defined at:\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 653, in launch_instance\n    app.start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-8f681eb118f8>\", line 7, in <module>\n    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py\", line 169, in constant\n    attrs={\"value\": tensor_value, \"dtype\": dtype_value}, name=name).outputs[0]\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device to node 'b': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0\n\t [[Node: b = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [3,2] values: [1 2][3]...>, _device=\"/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# training a CNN model \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "training_epochs = 30\n",
    "\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "layer_width = {\n",
    "    'layer_1': 32,\n",
    "    'layer_2': 64,\n",
    "    'layer_3': 128,\n",
    "    'fully_connected': 512\n",
    "}\n",
    "\n",
    "# layer 1 input 28x28x1\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'layer_1': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, 1, layer_width['layer_1']])),\n",
    "    'layer_2': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_1'], layer_width['layer_2']])),\n",
    "    'layer_3': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_2'], layer_width['layer_3']])),\n",
    "    'fully_connected': tf.Variable(tf.truncated_normal(\n",
    "        [4*4*128, layer_width['fully_connected']])),\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected'], n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'layer_1': tf.Variable(tf.zeros(layer_width['layer_1'])),\n",
    "    'layer_2': tf.Variable(tf.zeros(layer_width['layer_2'])),\n",
    "    'layer_3': tf.Variable(tf.zeros(layer_width['layer_3'])),\n",
    "    'fully_connected': tf.Variable(tf.zeros(layer_width['fully_connected'])),\n",
    "    'out': tf.Variable(tf.zeros(n_classes))\n",
    "}\n",
    "\n",
    "\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, k, k, 1],\n",
    "        strides=[1, k, k, 1],\n",
    "        padding='SAME')\n",
    "\n",
    "# Create model\n",
    "def conv_net(x, weights, biases):\n",
    "    # Layer 1 - 28*28*1 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['layer_1'], biases['layer_1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['layer_2'], biases['layer_2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "\n",
    "    # Layer 3 - 7*7*64 to 4*4*128\n",
    "    conv3 = conv2d(conv2, weights['layer_3'], biases['layer_3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "\n",
    "    # Fully connected layer - 4*4*128 to 512\n",
    "    # Reshape conv3 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(\n",
    "        conv3,\n",
    "        [-1, weights['fully_connected'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(\n",
    "        tf.matmul(fc1, weights['fully_connected']),\n",
    "        biases['fully_connected'])\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "\n",
    "    # Output Layer - class prediction - 512 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, 28, 28, 1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "logits = conv_net(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\\\n",
    "    .minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Display logs per epoch step\n",
    "        c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\n",
    "        \"Accuracy:\",\n",
    "        accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import _frozen_importlib # frozen\r\n",
      "import _imp # builtin\r\n",
      "import sys # builtin\r\n",
      "import '_warnings' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import '_thread' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import '_weakref' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import '_frozen_importlib_external' # <class '_frozen_importlib.FrozenImporter'>\r\n",
      "import '_io' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'marshal' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'posix' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import _thread # previously loaded ('_thread')\r\n",
      "import '_thread' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import _weakref # previously loaded ('_weakref')\r\n",
      "import '_weakref' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# installing zipimport hook\r\n",
      "import 'zipimport' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# installed zipimport hook\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/__init__.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__init__.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/__init__.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/codecs.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/codecs.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/codecs.cpython-35.pyc'\r\n",
      "import '_codecs' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'codecs' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edf4eb00>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/aliases.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/aliases.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/aliases.cpython-35.pyc'\r\n",
      "import 'encodings.aliases' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edee75f8>\r\n",
      "import 'encodings' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edf4e710>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/utf_8.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/utf_8.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/utf_8.cpython-35.pyc'\r\n",
      "import 'encodings.utf_8' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edef13c8>\r\n",
      "import '_signal' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/latin_1.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/latin_1.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/latin_1.cpython-35.pyc'\r\n",
      "import 'encodings.latin_1' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edef1eb8>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/io.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/io.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/io.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/abc.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/abc.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/abc.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_weakrefset.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/_weakrefset.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_weakrefset.cpython-35.pyc'\r\n",
      "import '_weakrefset' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edef3b70>\r\n",
      "import 'abc' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edef3390>\r\n",
      "import 'io' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edef3128>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/site.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/site.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/os.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/os.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/os.cpython-35.pyc'\r\n",
      "import 'errno' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/stat.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/stat.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/stat.cpython-35.pyc'\r\n",
      "import '_stat' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'stat' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede9f198>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/posixpath.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/posixpath.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/posixpath.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/genericpath.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/genericpath.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/genericpath.cpython-35.pyc'\r\n",
      "import 'genericpath' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edea0a20>\r\n",
      "import 'posixpath' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede9f4e0>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_collections_abc.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/_collections_abc.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_collections_abc.cpython-35.pyc'\r\n",
      "import '_collections_abc' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edeab0b8>\r\n",
      "import 'os' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edf09940>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_sitebuiltins.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/_sitebuiltins.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_sitebuiltins.cpython-35.pyc'\r\n",
      "import '_sitebuiltins' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edf09c18>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/sysconfig.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/sysconfig.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/sysconfig.cpython-35.pyc'\r\n",
      "import 'sysconfig' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede5f7f0>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_sysconfigdata.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/_sysconfigdata.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_sysconfigdata.cpython-35.pyc'\r\n",
      "import '_sysconfigdata' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede66128>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_bootlocale.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/_bootlocale.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/_bootlocale.cpython-35.pyc'\r\n",
      "import '_locale' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import '_bootlocale' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede72278>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/types.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/types.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/types.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/functools.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/functools.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/functools.cpython-35.pyc'\r\n",
      "import '_functools' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/__pycache__/__init__.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/__init__.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/__pycache__/__init__.cpython-35.pyc'\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/operator.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/operator.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/operator.cpython-35.pyc'\r\n",
      "import '_operator' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'operator' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec703710>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/keyword.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/keyword.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/keyword.cpython-35.pyc'\r\n",
      "import 'keyword' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec70fa20>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/heapq.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/heapq.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/heapq.cpython-35.pyc'\r\n",
      "# extension module '_heapq' loaded from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/lib-dynload/_heapq.so'\r\n",
      "# extension module '_heapq' executed from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/lib-dynload/_heapq.so'\r\n",
      "import '_heapq' # <_frozen_importlib_external.ExtensionFileLoader object at 0x7ff8ec7119e8>\r\n",
      "import 'heapq' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec7112e8>\r\n",
      "import 'itertools' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/reprlib.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/reprlib.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/reprlib.cpython-35.pyc'\r\n",
      "import 'reprlib' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec711ac8>\r\n",
      "import '_collections' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "import 'collections' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede92198>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/weakref.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/weakref.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/weakref.cpython-35.pyc'\r\n",
      "import 'weakref' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec71c6a0>\r\n",
      "import 'functools' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede81e48>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/__pycache__/abc.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/abc.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/collections/__pycache__/abc.cpython-35.pyc'\r\n",
      "import 'collections.abc' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede88e10>\r\n",
      "import 'types' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ede811d0>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/cp437.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/cp437.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/encodings/__pycache__/cp437.cpython-35.pyc'\r\n",
      "import 'encodings.cp437' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec4b5278>\r\n",
      "# zipimport: found 126 names in '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg'\r\n",
      "import 'site' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8edf054a8>\r\n",
      "Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:53:06) \r\n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\r\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n",
      "# extension module 'readline' loaded from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/lib-dynload/readline.so'\r\n",
      "# extension module 'readline' executed from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/lib-dynload/readline.so'\r\n",
      "import 'readline' # <_frozen_importlib_external.ExtensionFileLoader object at 0x7ff8ede8d550>\r\n",
      "import 'atexit' # <class '_frozen_importlib.BuiltinImporter'>\r\n",
      "# /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/rlcompleter.cpython-35.pyc matches /home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/rlcompleter.py\r\n",
      "# code object from '/home/pemfir/anaconda3/envs/tensorflow/lib/python3.5/__pycache__/rlcompleter.cpython-35.pyc'\r\n",
      "import 'rlcompleter' # <_frozen_importlib_external.SourceFileLoader object at 0x7ff8ec4b5320>\r\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!python -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'add:0' shape=(1, 2, 2, 3) dtype=float32>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "#     weight = tf.Variable(tf.truncated_normal(\n",
    "#         [filter_size_width, filter_size_height, color_channels, k_output]))\n",
    "#     bias = tf.Variable(tf.zeros(k_output))    \n",
    "# when you use 'VALID' the folllowing expression hold\n",
    "# out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "# out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "    F_W = tf.Variable(tf.truncated_normal([2, 2, 1, 3]))\n",
    "    F_b = tf.Variable(tf.zeros(3))       \n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n",
    "\n",
    "out.get_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'MaxPool:0' shape=(1, 2, 2, 1) dtype=float32>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "#     I want to transform the input shape (1, 4, 4, 1) to (1, 2, 2, 1). I choose 'VALID' for the padding algorithm. I find it simpler to understand and it achieves the result I'm looking for.\n",
    "\n",
    "# out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "# out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)\n",
    "\n",
    "out.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'layer_1': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, 1, layer_width['layer_1']])),\n",
    "    'layer_2': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_1'], layer_width['layer_2']])),\n",
    "    'layer_3': tf.Variable(tf.truncated_normal(\n",
    "        [5, 5, layer_width['layer_2'], layer_width['layer_3']])),\n",
    "    'fully_connected': tf.Variable(tf.truncated_normal(\n",
    "        [4*4*128, layer_width['fully_connected']])),\n",
    "    'out': tf.Variable(tf.truncated_normal(\n",
    "        [layer_width['fully_connected'], n_classes]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
