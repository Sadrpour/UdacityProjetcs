{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.platform.flags.DEFINE_integer>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.datasets import cifar10\n",
    "# (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train = X_train / 255 - 0.5\n",
    "# X_test = X_test / 255 - 0.5\n",
    "\n",
    "# TODO: Re-construct the network and add dropout after the pooling layer.\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_3 (Flatten)              (None, 512)           0           flatten_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           65664       flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 128)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            1290        dropout_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 66,954\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "(1000, 1, 1, 512) (1000, 10)\n",
      "(10000, 1, 1, 512) (10000, 10)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_4 (Flatten)              (None, 512)           0           flatten_input_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 128)           65664       flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 128)           0           dense_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 10)            1290        dropout_10[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 66,954\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "0s - loss: 4.3272 - acc: 0.1850 - val_loss: 1.6680 - val_acc: 0.5060\n",
      "Epoch 2/30\n",
      "0s - loss: 2.0305 - acc: 0.4070 - val_loss: 1.2701 - val_acc: 0.6750\n",
      "Epoch 3/30\n",
      "0s - loss: 1.5477 - acc: 0.5600 - val_loss: 1.0323 - val_acc: 0.7750\n",
      "Epoch 4/30\n",
      "0s - loss: 1.2740 - acc: 0.6370 - val_loss: 0.8591 - val_acc: 0.8180\n",
      "Epoch 5/30\n",
      "0s - loss: 1.1946 - acc: 0.6750 - val_loss: 0.7516 - val_acc: 0.8700\n",
      "Epoch 6/30\n",
      "0s - loss: 0.9973 - acc: 0.7250 - val_loss: 0.6645 - val_acc: 0.8750\n",
      "Epoch 7/30\n",
      "0s - loss: 0.9084 - acc: 0.7590 - val_loss: 0.5881 - val_acc: 0.9070\n",
      "Epoch 8/30\n",
      "0s - loss: 0.8357 - acc: 0.7780 - val_loss: 0.5391 - val_acc: 0.9180\n",
      "Epoch 9/30\n",
      "0s - loss: 0.7960 - acc: 0.8070 - val_loss: 0.4895 - val_acc: 0.9300\n",
      "Epoch 10/30\n",
      "0s - loss: 0.6986 - acc: 0.8300 - val_loss: 0.4456 - val_acc: 0.9480\n",
      "Epoch 11/30\n",
      "0s - loss: 0.6387 - acc: 0.8610 - val_loss: 0.4059 - val_acc: 0.9470\n",
      "Epoch 12/30\n",
      "0s - loss: 0.6316 - acc: 0.8570 - val_loss: 0.3743 - val_acc: 0.9600\n",
      "Epoch 13/30\n",
      "0s - loss: 0.5919 - acc: 0.8590 - val_loss: 0.3584 - val_acc: 0.9700\n",
      "Epoch 14/30\n",
      "0s - loss: 0.5432 - acc: 0.8960 - val_loss: 0.3377 - val_acc: 0.9790\n",
      "Epoch 15/30\n",
      "0s - loss: 0.5151 - acc: 0.9010 - val_loss: 0.3215 - val_acc: 0.9850\n",
      "Epoch 16/30\n",
      "0s - loss: 0.4903 - acc: 0.9170 - val_loss: 0.3094 - val_acc: 0.9840\n",
      "Epoch 17/30\n",
      "0s - loss: 0.4509 - acc: 0.9210 - val_loss: 0.2915 - val_acc: 0.9940\n",
      "Epoch 18/30\n",
      "0s - loss: 0.4457 - acc: 0.9300 - val_loss: 0.2773 - val_acc: 0.9950\n",
      "Epoch 19/30\n",
      "0s - loss: 0.4534 - acc: 0.9240 - val_loss: 0.2775 - val_acc: 0.9980\n",
      "Epoch 20/30\n",
      "0s - loss: 0.4089 - acc: 0.9330 - val_loss: 0.2709 - val_acc: 1.0000\n",
      "Epoch 21/30\n",
      "0s - loss: 0.4052 - acc: 0.9440 - val_loss: 0.2569 - val_acc: 1.0000\n",
      "Epoch 22/30\n",
      "0s - loss: 0.3958 - acc: 0.9400 - val_loss: 0.2499 - val_acc: 1.0000\n",
      "Epoch 23/30\n",
      "0s - loss: 0.3524 - acc: 0.9620 - val_loss: 0.2439 - val_acc: 1.0000\n",
      "Epoch 24/30\n",
      "0s - loss: 0.3718 - acc: 0.9430 - val_loss: 0.2416 - val_acc: 1.0000\n",
      "Epoch 25/30\n",
      "0s - loss: 0.3753 - acc: 0.9490 - val_loss: 0.2341 - val_acc: 1.0000\n",
      "Epoch 26/30\n",
      "0s - loss: 0.3726 - acc: 0.9520 - val_loss: 0.2315 - val_acc: 1.0000\n",
      "Epoch 27/30\n",
      "0s - loss: 0.3441 - acc: 0.9620 - val_loss: 0.2279 - val_acc: 1.0000\n",
      "Epoch 28/30\n",
      "0s - loss: 0.3467 - acc: 0.9540 - val_loss: 0.2248 - val_acc: 1.0000\n",
      "Epoch 29/30\n",
      "0s - loss: 0.3153 - acc: 0.9660 - val_loss: 0.2193 - val_acc: 1.0000\n",
      "Epoch 30/30\n",
      "0s - loss: 0.3295 - acc: 0.9600 - val_loss: 0.2184 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# %load feature_extractionv2.py\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.datasets import cifar10\n",
    "# (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "# Y_train = np_utils.to_categorical(y_train, 10)\n",
    "# Y_test = np_utils.to_categorical(y_test, 10)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_train = X_train / 255 - 0.5\n",
    "# X_test = X_test / 255 - 0.5\n",
    "\n",
    "# TODO: Re-construct the network and add dropout after the pooling layer.\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2, activity_l2\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3),W_regularizer=l2(0.000)))\n",
    "#model.add(MaxPooling2D((2,2)))\n",
    "#model.add((Dropout(0.5)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(64, 3, 3,W_regularizer=l2(0.000)))\n",
    "#model.add((Dropout(0.5)))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv2D(128, 3, 3,W_regularizer=l2(0.000)))\n",
    "#model.add(MaxPooling2D((2,2)))\n",
    "#model.add((Dropout(0.5)))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(Flatten(input_shape=(512,1,1,)))\n",
    "model.add(Dense(128, activation='relu',W_regularizer=l2(0.001)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Dense(10, activation='softmax',W_regularizer=l2(0.001)))\n",
    "model.summary()\n",
    "# flags = tf.app.flags\n",
    "# FLAGS = flags.FLAGS\n",
    "\n",
    "# command line flags\n",
    "# flags.DEFINE_string('training_file', '', \"Bottleneck features training file (.p)\")\n",
    "# flags.DEFINE_string('validation_file', '', \"Bottleneck features validation file (.p)\")\n",
    "\n",
    "training_file = 'vgg_cifar10_100_bottleneck_features_train.p'\n",
    "validation_file = 'vgg_cifar10_bottleneck_features_validation.p'\n",
    "# def load_bottleneck_data(training_file, validation_file):\n",
    "#     \"\"\"\n",
    "#     Utility function to load bottleneck features.\n",
    "\n",
    "#     Arguments:\n",
    "#         training_file - String\n",
    "#         validation_file - String\n",
    "#     \"\"\"\n",
    "#     print(\"Training file\", training_file)\n",
    "#     print(\"Validation file\", validation_file)\n",
    "\n",
    "with open(training_file, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(validation_file, 'rb') as f:\n",
    "    validation_data = pickle.load(f)\n",
    "\n",
    "X_train = train_data['features']\n",
    "y_train = train_data['labels']\n",
    "X_val = validation_data['features']\n",
    "y_val = validation_data['labels']\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_val = np_utils.to_categorical(y_val, 10)\n",
    "#     return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "# def main(_):\n",
    "    # load bottleneck data\n",
    "#     X_train, y_train, X_val, y_val = load_bottleneck_data(FLAGS.training_file, FLAGS.validation_file)\n",
    "# X_train, y_train, X_val, y_val = load_bottleneck_data(training_file, validation_file)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "    # TODO: define your model and hyperparams here\n",
    "    # make sure to adjust the number of classes based on\n",
    "    # the dataset\n",
    "    # 10 for cifar10\n",
    "    # 43 for traffic\n",
    "model = Sequential()\n",
    "# inp = Input(shape=(1,1,512))\n",
    "model.add(Flatten(input_shape=(1, 1, 512)))\n",
    "model.add(Dense(128, activation='relu',W_regularizer=l2(0.001)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Dense(10, activation='softmax',W_regularizer=l2(0.001)))\n",
    "model.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "opt = keras.optimizers.Nadam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=128, nb_epoch=30,\n",
    "                    verbose=2, validation_data=(X_train, y_train))\n",
    "    # TODO: train your model here\n",
    "\n",
    "\n",
    "# parses flags and calls the `main` function above\n",
    "# if __name__ == '__main__':\n",
    "#     tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_4 (Convolution2D)  (None, 30, 30, 32)    896         convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 15, 15, 32)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 15, 15, 32)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 15, 15, 32)    0           dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 13, 13, 64)    18496       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 13, 13, 64)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 13, 13, 64)    0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 11, 11, 128)   73856       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 5, 5, 128)     0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 5, 5, 128)     0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 5, 5, 128)     0           dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 3200)          0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 128)           409728      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 128)           0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 10)            1290        dropout_8[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 504,266\n",
      "Trainable params: 504,266\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Train on 50000 samples, validate on 50000 samples\n",
      "Epoch 1/5\n",
      "9s - loss: 1.8585 - acc: 0.3506 - val_loss: 1.5276 - val_acc: 0.4918\n",
      "Epoch 2/5\n",
      "6s - loss: 1.6081 - acc: 0.4600 - val_loss: 1.4532 - val_acc: 0.5328\n",
      "Epoch 3/5\n",
      "7s - loss: 1.5400 - acc: 0.4965 - val_loss: 1.3536 - val_acc: 0.5780\n",
      "Epoch 4/5\n",
      "6s - loss: 1.4865 - acc: 0.5218 - val_loss: 1.3322 - val_acc: 0.6001\n",
      "Epoch 5/5\n",
      "7s - loss: 1.4462 - acc: 0.5417 - val_loss: 1.2901 - val_acc: 0.6114\n",
      "10000/10000 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3135204696655274, 0.60109999999999997]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Activation\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255 - 0.5\n",
    "X_test = X_test / 255 - 0.5\n",
    "\n",
    "# TODO: Re-construct the network and add dropout after the pooling layer.\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2, activity_l2\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 3, 3, input_shape=(32, 32, 3),W_regularizer=l2(0.000)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, 3, 3,W_regularizer=l2(0.000)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, 3, 3,W_regularizer=l2(0.000)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu',W_regularizer=l2(0.001)))\n",
    "model.add((Dropout(0.5)))\n",
    "model.add(Dense(10, activation='softmax',W_regularizer=l2(0.001)))\n",
    "\n",
    "model.summary()\n",
    "# TODO: Compile and train the model here.\n",
    "opt = keras.optimizers.Nadam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=128, nb_epoch=5,\n",
    "                    verbose=2, validation_data=(X_train, y_train))\n",
    "\n",
    "\n",
    "# testing_file = '/media/pemfir/Data/docker/lab 2 data/test2.p'\n",
    "\n",
    "\n",
    "    \n",
    "# TODO: Preprocess data & one-hot encode the labels\n",
    "\n",
    "# TODO: Evaluate model on test data\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND-LeNet-Lab]",
   "language": "python",
   "name": "conda-env-CarND-LeNet-Lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
